<mat-card class="card">
  <mat-card-title>Morgan Stanley <i>- Software Developer</i></mat-card-title>
  <mat-card-subtitle>Montreal QC</mat-card-subtitle>
  <mat-card-subtitle>Major Technologies Used: C++, Python, SQL, KDB</mat-card-subtitle>
  <mat-card-subtitle>2017 June - 2019 May</mat-card-subtitle>
  <mat-card-content>

    <h3>Corvil Data</h3>
    <ul>
      <li>
        Wrote processes in <strong>Python</strong> to collect network data and ran analytics in the firm to determine
        end-to-end latency across multiple processes to track down <strong>bottlenecks</strong>.
      </li>
      <li>
        Dealt with <strong>big data</strong>, in order to keep up with data flow we needed to highly parallelize and
        streamline our program. This included a <strong>parallel pipeline</strong> and threads for each channel and
        region. As well as a highly efficient custom <strong>compression/decompression</strong> algorithm written in
        house by us in <strong>C++</strong> which kept the desired subset of data we wanted to analyze and compressed
        the data into a binary format which would need to be sent across our internal networks.
      </li>
      <li>
        Collected information about several processes across the firm and all of the hosts and ports that they
        were listening and sending data from. Then stored this information in a <strong>SQLite</strong> database which
        was used by several programs across the firm.
      </li>
      <li>
        Collected not only fully formed messages but also <strong>TCP</strong> packets which gave us a very detailed
        view of the data flow and things such as TCP window sizes to allow us to track down slow consumers and notify
        client's whose machines were unable to keep up with our data.
      </li>
      <li>
        Dealt with <strong>Multicast, Infiniband and Soap protocols</strong>.
      </li>
    </ul>

    <h3>Client Gateway</h3>
    <ul>
      <li>
        Developed a <strong>Rest API</strong> with <strong>Python Flask</strong>.
      </li>
      <li>
        Deployed API to 15 servers spread across New York, London, and Tokyo listening 24/7 for requests.
      </li>
      <li>
        Used <strong>Kerberos</strong> authentication combined with <strong>JSON web tokens</strong> and stringent
        audit logs for <strong>security</strong>.
      </li>
      <li>
        Developed a client script to regularly make requests to servers in parallel to collect data about client
        interactions.
      </li>
      <li>
        Capable of sending very large quantities of data over network and handling <strong>high volume of
        requests</strong>.
      </li>
      <li>
        Able to stream large files in small chunks using on-the-fly <strong>compression</strong>.
      </li>
    </ul>

    <h3>Back Testing</h3>
    <ul>
      <li>
        Collected and aggregated historical data from <strong>KDB</strong> databases, processed it into a format
        understood by our processes, and used it to replay into our <strong>pricing engine</strong>.
      </li>
      <li>
        Ran across a powerset of different input and pricing engine configurations to compare performance.
      </li>
      <li>
        Developed a tool to abstract a convoluted process of getting KDB data off of several different hosts into an
        intuitive, easy-to-use API developed with <strong>Paramiko</strong> for <strong>SSH</strong> tunneling which
        was used by many teams across multiple projects.
      </li>
      <li>
        Since historical data only tracks deltas for performance reasons, we must iterate backwards through time in
        data until we can achieve a fully populated state-of-world for any given time interval.
       </li>
      <li>
        Aggregate and merge data using a custom linear <strong>merge sort</strong> algorithm.
      </li>
    </ul>

    <h3>Pricing Engine</h3>
    <ul>
      <li>
        Wrote <strong>C++</strong> to contribute to a high performance and low latency pricing engine for
        <strong>foreign exchange</strong> markets.
      </li>
      <li>
        Gained experience working on very large code base shared among multiple talented and experienced senior
        developers.
      </li>
    </ul>

  </mat-card-content>
</mat-card>

<mat-card class="card">
  <mat-card-title>Signiant <i>- Software Developer</i></mat-card-title>
  <mat-card-subtitle>Ottawa ON</mat-card-subtitle>
  <mat-card-subtitle>Major Technologies Used: Go, NodeJS, Python</mat-card-subtitle>
  <mat-card-subtitle>2019 May - Present</mat-card-subtitle>
  <mat-card-content>

  <h3>Hot Config</h3>
    <ul>
      <li>
        Added new endpoints to <strong>Go Rest API</strong> to read and update configuration of program on server.
      </li>
      <li>
        Able to modify all configurable attributes of program including url's, ports, level of
        parallelism of transfers, log level, etc. without needing to restart process.
      </li>
      <li>
        Possible to take any subset of config and merge it with current config.
      </li>
      <li>
        Wrote integration tests to query API with <strong>NodeJS</strong>
      </li>
    </ul>
  <h3>Delete After Transfer</h3>
    <ul>
      <li>
        Created customizable file remover to remove files after transferring them across the network.
      </li>
      <li>
        Able to recursively walk directories and remove all sub-content if specified as well as exclude certain files
        if they match a regular expression or were last modified after a certain date-time.
      </li>
      <li>
        Would send post requests to cloud to confirm if a file was successfully removed or not.
      </li>
    </ul>
  </mat-card-content>
</mat-card>
